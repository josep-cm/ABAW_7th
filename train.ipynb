{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.utils.data as data\n",
    "#from networks.DDAM import DDAMNet\n",
    "from networks.DDAM_ABAW import DDAMNet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to freeze all layers\n",
    "def freeze_all_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_all_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Function to unfreeze specific layers\n",
    "def unfreeze_layers(model, layer_names):\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer_name in name for layer_name in layer_names):\n",
    "            param.requires_grad = True\n",
    "\n",
    "def freeze_batchnorm_layers(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
    "            module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the test_transforms outside the class\n",
    "IMG_SIZE = 112\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])  \n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([\n",
    "                transforms.RandomAffine(20, scale=(0.8, 1), translate=(0.2, 0.2)),\n",
    "            ], p=0.7),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=1, scale=(0.05, 0.05)),\n",
    "        ])\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, main_folder, mode, batch_size=32, image_size=(260, 260), n_classes_3=8, shuffle=True, device='cpu', transforms=test_transforms):\n",
    "        'Initialization'\n",
    "        self.main_folder = main_folder\n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.n_classes_3 = n_classes_3\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.device = device\n",
    "        self.transforms = transforms\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            self.targets_csv = '../keras_vggface_master/filtered_training_set_annotations.csv'\n",
    "        elif self.mode == 'val':\n",
    "            self.targets_csv = '../keras_vggface_master/filtered_validation_set_annotations.csv'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Mode must be 'train' or 'val'.\")\n",
    "\n",
    "        # Load the CSV to get the total number of samples\n",
    "        self.targets_df = pd.read_csv(self.targets_csv)\n",
    "        self.list_IDs = self.targets_df.index.tolist()\n",
    "\n",
    "        \n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, 3, *self.image_size), dtype=np.float32)\n",
    "        y = [[] for _ in range(3)]  # Assuming 3 target arrays (valence/arousal, emotions, actions)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            row = self.targets_df.iloc[ID]\n",
    "            image_path = os.path.join(self.main_folder, row['image'])\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            # Apply transformations\n",
    "            image = self.transforms(image)\n",
    "            X[i,] = image.numpy()\n",
    "\n",
    "            y[0].append([row[1], row[2]])  # First target value (valence/arousal)\n",
    "            target_3_one_hot = to_categorical(row[3], num_classes=self.n_classes_3)\n",
    "            y[1].append(target_3_one_hot)\n",
    "            \n",
    "            y[2].append([row[col_start] for col_start in range(4, len(row))])\n",
    "            \n",
    "\n",
    "\n",
    "        X_tensor = torch.tensor(X).to(self.device)\n",
    "        y_tensor = [torch.tensor(np.array(sublist)).to(self.device) for sublist in y]  # Convert each sublist to tensor\n",
    "\n",
    "    \n",
    "        \n",
    "        return X_tensor, y_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "# Initialize the generator\n",
    "train_loader = DataGenerator(\"../cropped_aligned\", mode=\"train\", batch_size=32, image_size=(112, 112), shuffle=True, device='cuda', transforms=train_transforms)\n",
    "test_loader = DataGenerator(\"../cropped_aligned\",mode=\"val\",batch_size=32 ,image_size=(112,112), shuffle=False, device='cuda', transforms=test_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def CCC(y_true, y_pred):\n",
    "    y_true_mean = torch.mean(y_true)\n",
    "    y_pred_mean = torch.mean(y_pred)\n",
    "    covariance = torch.mean((y_true - y_true_mean) * (y_pred - y_pred_mean))\n",
    "    y_true_var = torch.var(y_true)\n",
    "    y_pred_var = torch.var(y_pred)\n",
    "    ccc = (2 * covariance) / (y_true_var + y_pred_var + (y_true_mean - y_pred_mean)**2 + 1e-8)\n",
    "    return ccc\n",
    "\n",
    "def CCC_loss(y_true, y_pred):\n",
    "    return 1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Positives = torch.sum(torch.round(torch.clamp(y_true, 0, 1)))\n",
    "        recall = TP / (Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return recall \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = torch.sum(torch.round(torch.clamp(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return precision \n",
    "    \n",
    "    # Initialize lists to store precision, recall, and f1 scores per class\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "\n",
    "    # Iterate over each class\n",
    "    for class_idx in range(y_true.shape[1]):\n",
    "        precision = precision_m(y_true[:, class_idx], y_pred[:, class_idx])\n",
    "        recall = recall_m(y_true[:, class_idx], y_pred[:, class_idx])\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * ((precision * recall) / (precision + recall + 1e-7))\n",
    "        \n",
    "        # Append scores to lists\n",
    "        precision_per_class.append(precision.item())\n",
    "        recall_per_class.append(recall.item())\n",
    "        f1_per_class.append(f1.item())\n",
    "    \n",
    "    # Overall macro F1 score\n",
    "    macro_f1 = torch.mean(torch.tensor(f1_per_class))\n",
    "    \n",
    "    # Return overall F1 score and F1 score per class\n",
    "    return macro_f1.item(), f1_per_class\n",
    "\n",
    "def f1_metric_o(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Positives = torch.sum(torch.round(torch.clamp(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return recall \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = torch.sum(torch.round(torch.clamp(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return precision \n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    \n",
    "    f1 = 2 * ((precision * recall) / (precision + recall + 1e-7))  # Adding a small epsilon for numerical stability\n",
    "    \n",
    "    return f1, f1\n",
    "\n",
    "def f1_score_actions(y_true, y_pred, threshold=0.5):\n",
    "    # Convert predicted probabilities to binary predictions\n",
    "    y_pred_binary = (y_pred >= threshold).float()\n",
    "    \n",
    "    # Initialize lists to store F1 scores for each AU\n",
    "    F1s = []\n",
    "    \n",
    "    # Calculate F1 score for each AU\n",
    "    for i in range(y_true.shape[1]):\n",
    "        # Extract true and predicted values for the current AU\n",
    "        y_true_au = y_true[:, i]\n",
    "        y_pred_au = y_pred_binary[:, i]\n",
    "        \n",
    "        # Calculate True Positives, False Positives, False Negatives\n",
    "        TP = torch.sum(y_true_au * y_pred_au)\n",
    "        FP = torch.sum((1 - y_true_au) * y_pred_au)\n",
    "        FN = torch.sum(y_true_au * (1 - y_pred_au))\n",
    "        \n",
    "        # Calculate Precision, Recall, and F1 Score\n",
    "        precision = TP / (TP + FP + 1e-7)  # Adding epsilon to avoid division by zero\n",
    "        recall = TP / (TP + FN + 1e-7)  # Adding epsilon to avoid division by zero\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-7)  # Adding epsilon to avoid division by zero\n",
    "        \n",
    "        F1s.append(f1.item())\n",
    "    \n",
    "    F1s = torch.tensor(F1s)\n",
    "    F1_mean = torch.mean(F1s)\n",
    "    \n",
    "    return F1s, F1_mean.item()\n",
    "\n",
    "\n",
    "def compute_AU_F1(pred,label):\n",
    "    pred = np.array(pred)\n",
    "    label = np.array(label)\n",
    "    AU_targets = [[] for i in range(12)]\n",
    "    AU_preds = [[] for i in range(12)]\n",
    "    F1s = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(12):\n",
    "            p = pred[i,j]\n",
    "            if p>=0.5:\n",
    "                AU_preds[j].append(1)\n",
    "            else:\n",
    "                AU_preds[j].append(0)\n",
    "            AU_targets[j].append(label[i,j])\n",
    "    \n",
    "    for i in range(12):\n",
    "        F1s.append(f1_score(AU_targets[i], AU_preds[i]))\n",
    "\n",
    "    F1s = np.array(F1s)\n",
    "    F1_mean = np.mean(F1s)\n",
    "    return F1s, F1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "eps = sys.float_info.epsilon\n",
    "class AttentionLoss(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(AttentionLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        num_head = len(x)\n",
    "        loss = 0\n",
    "        cnt = 0\n",
    "        if num_head > 1:\n",
    "            for i in range(num_head-1):\n",
    "                for j in range(i+1, num_head):\n",
    "                    mse = F.mse_loss(x[i], x[j])\n",
    "                    cnt = cnt+1\n",
    "                    loss = loss+mse\n",
    "            loss = cnt/(loss + eps)\n",
    "        else:\n",
    "            loss = 0\n",
    "        return loss\n",
    "    \n",
    "\n",
    "def compute_EXP_F1(pred, target):\n",
    "    pred_labels = []\n",
    "    pred = np.array(pred)\n",
    "    target = np.array(target)\n",
    "    \n",
    "    # Convert one-hot encoded target to class labels\n",
    "    if len(target.shape) > 1 and target.shape[1] > 1:\n",
    "        target = np.argmax(target, axis=1)\n",
    "    \n",
    "    # Convert predictions to class labels\n",
    "    for i in range(pred.shape[0]):\n",
    "        l = np.argmax(pred[i])\n",
    "        pred_labels.append(l)\n",
    "        \n",
    "    # Compute F1 scores\n",
    "    F1s = f1_score(target, pred_labels, average=None)\n",
    "    macro_f1 = np.mean(F1s)\n",
    "    return F1s, macro_f1\n",
    "\n",
    "\n",
    "def compute_AU_F1(pred,label):\n",
    "    pred = np.array(pred)\n",
    "    label = np.array(label)\n",
    "    AU_targets = [[] for i in range(12)]\n",
    "    AU_preds = [[] for i in range(12)]\n",
    "    F1s = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(12):\n",
    "            p = pred[i,j]\n",
    "            if p>=0.5:\n",
    "                AU_preds[j].append(1)\n",
    "            else:\n",
    "                AU_preds[j].append(0)\n",
    "            AU_targets[j].append(label[i,j])\n",
    "    \n",
    "    for i in range(12):\n",
    "        F1s.append(f1_score(AU_targets[i], AU_preds[i]))\n",
    "\n",
    "    F1s = np.array(F1s)\n",
    "    F1_mean = np.mean(F1s)\n",
    "    return F1s, F1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:03<00:00,  6.68it/s]\n",
      "100%|██████████| 482/482 [00:55<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 3.3470557923203095\n",
      "Validation Loss: 3.609929886022399\n",
      "P_SCORE: 0.91736057578644\n",
      "Validation CCC (Valence-Arousal): 0.5185739818094095, Valence: 0.5101865759105156, Arousal: 0.5269613877083033\n",
      "F1 Score_ABAW (Emotions): 0.11846472770315049, F1 Score (Emotions per class): [0.10651408 0.         0.         0.         0.35430504 0.08370948\n",
      " 0.         0.40318922]\n",
      "F1 Score Mean (Actions): 0.28032186627388, F1 Score (Actions): tensor([0.0843, 0.0000, 0.1233, 0.5176, 0.6372, 0.5983, 0.5386, 0.0000, 0.0000,\n",
      "        0.0000, 0.8647, 0.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:02<00:00,  6.72it/s]\n",
      "100%|██████████| 482/482 [00:59<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 3.0676400856951984\n",
      "Validation Loss: 3.527181204583479\n",
      "P_SCORE: 1.070953974265749\n",
      "Validation CCC (Valence-Arousal): 0.5242830152742235, Valence: 0.5170409528529496, Arousal: 0.5315250776954975\n",
      "F1 Score_ABAW (Emotions): 0.18103282212781696, F1 Score (Emotions per class): [0.33629168 0.         0.         0.         0.44511387 0.34353268\n",
      " 0.         0.32332435]\n",
      "F1 Score Mean (Actions): 0.3656381368637085, F1 Score (Actions): tensor([0.4233, 0.0000, 0.4610, 0.5883, 0.7112, 0.6834, 0.6391, 0.0000, 0.0000,\n",
      "        0.0000, 0.8782, 0.0031])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:04<00:00,  6.67it/s]\n",
      "100%|██████████| 482/482 [00:57<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 2.9746261026671443\n",
      "Validation Loss: 3.498444934946681\n",
      "P_SCORE: 1.1327782331786518\n",
      "Validation CCC (Valence-Arousal): 0.5264980045804604, Valence: 0.5227169758677568, Arousal: 0.5302790332931638\n",
      "F1 Score_ABAW (Emotions): 0.1869051964116833, F1 Score (Emotions per class): [0.35596708 0.         0.         0.         0.46081505 0.390891\n",
      " 0.         0.28756844]\n",
      "F1 Score Mean (Actions): 0.4193750321865082, F1 Score (Actions): tensor([0.5072, 0.1647, 0.5216, 0.6077, 0.7264, 0.6938, 0.6640, 0.0000, 0.0000,\n",
      "        0.0000, 0.8791, 0.2678])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:00<00:00,  6.78it/s]\n",
      "100%|██████████| 482/482 [00:59<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 2.9312299563318436\n",
      "Validation Loss: 3.481685827012203\n",
      "P_SCORE: 1.1635384336579986\n",
      "Validation CCC (Valence-Arousal): 0.528784864073631, Valence: 0.5293035084443168, Arousal: 0.5282662197029452\n",
      "F1 Score_ABAW (Emotions): 0.1888150718026141, F1 Score (Emotions per class): [0.36098923 0.         0.         0.         0.46532003 0.39474291\n",
      " 0.         0.28946841]\n",
      "F1 Score Mean (Actions): 0.44593849778175354, F1 Score (Actions): tensor([0.5343, 0.3597, 0.5389, 0.6100, 0.7300, 0.6942, 0.6692, 0.0000, 0.0000,\n",
      "        0.0000, 0.8789, 0.3360])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:04<00:00,  6.66it/s]\n",
      "100%|██████████| 482/482 [00:57<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 2.894641619607972\n",
      "Validation Loss: 3.4669395134142795\n",
      "P_SCORE: 1.18392073539681\n",
      "Validation CCC (Valence-Arousal): 0.5344860334595474, Valence: 0.5303392827723098, Arousal: 0.5386327841467851\n",
      "F1 Score_ABAW (Emotions): 0.19543193413597781, F1 Score (Emotions per class): [0.35576148 0.         0.         0.         0.46963864 0.44013683\n",
      " 0.         0.29791852]\n",
      "F1 Score Mean (Actions): 0.4540027678012848, F1 Score (Actions): tensor([0.5432, 0.4076, 0.5669, 0.6127, 0.7310, 0.6941, 0.6673, 0.0000, 0.0000,\n",
      "        0.0000, 0.8777, 0.3475])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:12<00:00,  6.44it/s]\n",
      "100%|██████████| 482/482 [01:00<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 2.8688473952270384\n",
      "Validation Loss: 3.45267323273374\n",
      "P_SCORE: 1.189662959943581\n",
      "Validation CCC (Valence-Arousal): 0.534809271872571, Valence: 0.5356617069832431, Arousal: 0.5339568367618988\n",
      "F1 Score_ABAW (Emotions): 0.19674037534975758, F1 Score (Emotions per class): [0.36859035 0.         0.         0.         0.47680158 0.44364852\n",
      " 0.         0.28488255]\n",
      "F1 Score Mean (Actions): 0.45811331272125244, F1 Score (Actions): tensor([0.5471, 0.4302, 0.5652, 0.6143, 0.7355, 0.6965, 0.6746, 0.0000, 0.0000,\n",
      "        0.0000, 0.8775, 0.3566])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:14<00:00,  6.40it/s]\n",
      "100%|██████████| 482/482 [00:58<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 2.8475313133299323\n",
      "Validation Loss: 3.4451379300753824\n",
      "P_SCORE: 1.193634197274307\n",
      "Validation CCC (Valence-Arousal): 0.5338452661097426, Valence: 0.5355113183503262, Arousal: 0.532179213869159\n",
      "F1 Score_ABAW (Emotions): 0.1995418913696426, F1 Score (Emotions per class): [0.36603625 0.         0.         0.         0.47568632 0.45671927\n",
      " 0.         0.29789329]\n",
      "F1 Score Mean (Actions): 0.4602470397949219, F1 Score (Actions): tensor([0.5465, 0.4338, 0.5741, 0.6191, 0.7384, 0.6991, 0.6754, 0.0000, 0.0000,\n",
      "        0.0032, 0.8774, 0.3560])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:13<00:00,  6.43it/s]\n",
      "100%|██████████| 482/482 [01:02<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 2.8317017912763855\n",
      "Validation Loss: 3.4366591276934915\n",
      "P_SCORE: 1.1965346408331015\n",
      "Validation CCC (Valence-Arousal): 0.5333354841393373, Valence: 0.5352525579761824, Arousal: 0.5314184103024922\n",
      "F1 Score_ABAW (Emotions): 0.1988837422650532, F1 Score (Emotions per class): [0.36917222 0.         0.         0.         0.47511596 0.44384634\n",
      " 0.         0.30293542]\n",
      "F1 Score Mean (Actions): 0.46431541442871094, F1 Score (Actions): tensor([0.5504, 0.4387, 0.5809, 0.6120, 0.7359, 0.6979, 0.6728, 0.0000, 0.0000,\n",
      "        0.0440, 0.8775, 0.3617])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:22<00:00,  6.20it/s]\n",
      "100%|██████████| 482/482 [01:00<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Training Loss: 2.8139539826307853\n",
      "Validation Loss: 3.4321577487684567\n",
      "P_SCORE: 1.1972114496791462\n",
      "Validation CCC (Valence-Arousal): 0.5297402006594483, Valence: 0.5249775763413709, Arousal: 0.5345028249775255\n",
      "F1 Score_ABAW (Emotions): 0.20146398655135975, F1 Score (Emotions per class): [0.37333333 0.         0.         0.         0.47196086 0.4554356\n",
      " 0.         0.3109821 ]\n",
      "F1 Score Mean (Actions): 0.466007262468338, F1 Score (Actions): tensor([0.5493, 0.4359, 0.5781, 0.6114, 0.7366, 0.6990, 0.6734, 0.0000, 0.0000,\n",
      "        0.0739, 0.8767, 0.3579])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [04:24<00:00,  6.17it/s]\n",
      "100%|██████████| 482/482 [01:00<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Training Loss: 2.801183309550643\n",
      "Validation Loss: 3.4238161209916194\n",
      "P_SCORE: 1.2000599183992842\n",
      "Validation CCC (Valence-Arousal): 0.5283673433137288, Valence: 0.5223867485984302, Arousal: 0.5343479380290275\n",
      "F1 Score_ABAW (Emotions): 0.20439016329089277, F1 Score (Emotions per class): [0.37962425 0.         0.         0.         0.47676162 0.45537525\n",
      " 0.         0.32336018]\n",
      "F1 Score Mean (Actions): 0.4673024117946625, F1 Score (Actions): tensor([0.5473, 0.4405, 0.5692, 0.6112, 0.7391, 0.7007, 0.6757, 0.0000, 0.0000,\n",
      "        0.0885, 0.8773, 0.3583])\n"
     ]
    }
   ],
   "source": [
    "# Define the train and evaluation functions\n",
    "def train_model(model, train_loader, optimizer, criterion_val_arousal=None, criterion_emotions=None, criterion_actions=None, criterion_at=None, device=None, challenges=('val_arousal', 'emotions', 'actions')):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels_val_arousal = labels[0].to(device) if 'val_arousal' in challenges else None\n",
    "        labels_emotions = labels[1].to(device) if 'emotions' in challenges else None\n",
    "        labels_actions = labels[2].to(device) if 'actions' in challenges else None\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        val_arousal = outputs[0] if 'val_arousal' in challenges else None\n",
    "        emotions = outputs[1] if 'emotions' in challenges else None\n",
    "        actions = outputs[2] if 'actions' in challenges else None\n",
    "        heads = outputs[-1] if criterion_at else None\n",
    "        \n",
    "        loss = 0.0\n",
    "        if 'val_arousal' in challenges:\n",
    "            loss_val_arousal = criterion_val_arousal(val_arousal, labels_val_arousal)\n",
    "            loss += loss_val_arousal\n",
    "        if 'emotions' in challenges:\n",
    "            emotions_argmax = torch.argmax(labels_emotions, dim=1)\n",
    "            loss_emotions = criterion_emotions(emotions, emotions_argmax)\n",
    "            loss += loss_emotions\n",
    "        if 'actions' in challenges:\n",
    "            loss_actions = criterion_actions(actions.float(), labels_actions.float())\n",
    "            loss += loss_actions\n",
    "        if criterion_at:\n",
    "            loss += 0.1 * criterion_at(heads)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion_val_arousal=None, criterion_emotions=None, criterion_actions=None, criterion_at=None, device=None, challenges=('val_arousal', 'emotions', 'actions')):\n",
    "    model.eval()\n",
    "    val_arousal_preds, emotions_preds, actions_preds = [], [], []\n",
    "    val_arousal_labels, emotions_labels, actions_labels = [], [], []\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels_val_arousal = labels[0].to(device) if 'val_arousal' in challenges else None\n",
    "            labels_emotions = labels[1].to(device) if 'emotions' in challenges else None\n",
    "            labels_actions = labels[2].to(device) if 'actions' in challenges else None\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            val_arousal = outputs[0] if 'val_arousal' in challenges else None\n",
    "            emotions = outputs[1] if 'emotions' in challenges else None\n",
    "            actions = outputs[2] if 'actions' in challenges else None\n",
    "            heads = outputs[-1] if criterion_at else None\n",
    "            \n",
    "            loss = 0.0\n",
    "            if 'val_arousal' in challenges:\n",
    "                loss_val_arousal = criterion_val_arousal(val_arousal, labels_val_arousal)\n",
    "                loss += loss_val_arousal\n",
    "                val_arousal_preds.append(val_arousal.cpu())\n",
    "                val_arousal_labels.append(labels_val_arousal.cpu())\n",
    "            if 'emotions' in challenges:\n",
    "                emotions_argmax = torch.argmax(labels_emotions, dim=1)\n",
    "                loss_emotions = criterion_emotions(emotions, emotions_argmax)\n",
    "                loss += loss_emotions\n",
    "                emotions_preds.append(emotions.cpu())\n",
    "                emotions_labels.append(labels_emotions.cpu())\n",
    "            if 'actions' in challenges:\n",
    "                loss_actions = criterion_actions(actions.float(), labels_actions.float())\n",
    "                loss += loss_actions\n",
    "                actions_preds.append(actions.cpu())\n",
    "                actions_labels.append(labels_actions.cpu())\n",
    "            if criterion_at:\n",
    "                loss += 0.1 * criterion_at(heads)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(test_loader)\n",
    "\n",
    "    ccc_val_arousal = ccc_valence = ccc_arousal = None\n",
    "    f1_emotions = f1_emotion_mean = None\n",
    "    f1_actions = f1_mean = None\n",
    "\n",
    "    if 'val_arousal' in challenges:\n",
    "        val_arousal_preds = torch.cat(val_arousal_preds)\n",
    "        val_arousal_labels = torch.cat(val_arousal_labels)\n",
    "        ccc_valence = CCC(val_arousal_labels[:, 0].cpu(), val_arousal_preds[:, 0].cpu()).item()\n",
    "        ccc_arousal = CCC(val_arousal_labels[:, 1].cpu(), val_arousal_preds[:, 1].cpu()).item()\n",
    "        ccc_val_arousal = (ccc_valence + ccc_arousal) / 2\n",
    "    if 'emotions' in challenges:\n",
    "        emotions_preds = torch.cat(emotions_preds)\n",
    "        emotions_labels = torch.cat(emotions_labels)\n",
    "        f1_emotions, f1_emotion_mean = compute_EXP_F1(emotions_preds, emotions_labels)\n",
    "    if 'actions' in challenges:\n",
    "        actions_preds = torch.cat(actions_preds)\n",
    "        actions_labels = torch.cat(actions_labels)\n",
    "        f1_actions, f1_mean = f1_score_actions(actions_labels, actions_preds, threshold=0.5)\n",
    "\n",
    "    return ccc_val_arousal, ccc_valence, ccc_arousal, f1_emotions, f1_actions, avg_val_loss, f1_mean, f1_emotion_mean\n",
    "\n",
    "\n",
    "\n",
    "challenges=('val_arousal', 'emotions', 'actions')\n",
    "num_epochs = 10\n",
    "learning_rate = 0.00001\n",
    "model_path = 'checkpoints_ver2.0/affecnet8_epoch25_acc0.6469.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define dataloaders (placeholders, replace with actual DataLoader instances)\n",
    "from tqdm import tqdm\n",
    "# Initialize the generator\n",
    "train_loader = DataGenerator(\"../cropped_aligned\", mode=\"train\", batch_size=32, image_size=(112, 112), shuffle=True, device='cuda', transforms=train_transforms)\n",
    "test_loader = DataGenerator(\"../cropped_aligned\",mode=\"val\",batch_size=32 ,image_size=(112,112), shuffle=False, device='cuda', transforms=test_transforms)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_val_arousal = CCC_loss\n",
    "criterion_emotions = nn.CrossEntropyLoss()\n",
    "criterion_actions = nn.BCELoss()\n",
    "criterion_at = AttentionLoss()\n",
    "\n",
    "# Multitask Model Training\n",
    "model = DDAMNet(num_class=8, num_head=2, pretrained=False, train_val_arousal=True, train_emotions=True, train_actions=True)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "freeze_all_layers(model)\n",
    "layers_to_unfreeze = ['custom_classifier', \"Linear\",\"cat_head\"]#\"cat_head\",,\"features\"\n",
    "unfreeze_layers(model, layers_to_unfreeze)\n",
    "#freeze_batchnorm_layers(model)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "best_P_Score = float('-inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    results = evaluate_model(model, test_loader, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    P_score = results[0] + (results[7] or 0) + (results[6] or 0)\n",
    "    val_loss = results[5]\n",
    "    if P_score > best_P_Score:\n",
    "        best_P_Score = P_score\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    print(f\"P_SCORE: {results[0] + (results[7] or 0) + (results[6] or 0)}\")\n",
    "    if 'val_arousal' in challenges:\n",
    "        print(f\"Validation CCC (Valence-Arousal): {results[0]}, Valence: {results[1]}, Arousal: {results[2]}\")\n",
    "    if 'emotions' in challenges:\n",
    "        print(f\"F1 Score_ABAW (Emotions): {results[7]}, F1 Score (Emotions per class): {results[3]}\")\n",
    "    if 'actions' in challenges:\n",
    "        print(f\"F1 Score Mean (Actions): {results[6]}, F1 Score (Actions): {results[4]}\")\n",
    "\n",
    "    torch.save(best_model_state, 'best_multitask_model_att.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [07:28<00:00,  3.64it/s]\n",
      "100%|██████████| 482/482 [00:56<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 2.179194699220499\n",
      "Validation Loss: 3.418726620997506\n",
      "P_SCORE: 1.2632269316182152\n",
      "Validation CCC (Valence-Arousal): 0.5160456287627966, Valence: 0.5195258582165752, Arousal: 0.5125653993090179\n",
      "F1 Score_ABAW (Emotions): 0.2684003179768786, F1 Score (Emotions per class): [0.40840446 0.25459689 0.         0.17455439 0.44194646 0.28571429\n",
      " 0.15100671 0.43097934]\n",
      "F1 Score Mean (Actions): 0.47878098487854004, F1 Score (Actions): tensor([0.5865, 0.4185, 0.5463, 0.5995, 0.7601, 0.7123, 0.6780, 0.0000, 0.0000,\n",
      "        0.2325, 0.8780, 0.3336])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [07:24<00:00,  3.66it/s]\n",
      "100%|██████████| 482/482 [00:55<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 2.1605662478534557\n",
      "Validation Loss: 3.4105747809590055\n",
      "P_SCORE: 1.2514121646153926\n",
      "Validation CCC (Valence-Arousal): 0.5085011272187603, Valence: 0.5124890725616715, Arousal: 0.504513181875849\n",
      "F1 Score_ABAW (Emotions): 0.26705792207642653, F1 Score (Emotions per class): [0.41954507 0.25285714 0.         0.20934159 0.45333732 0.22249793\n",
      " 0.14701042 0.43187391]\n",
      "F1 Score Mean (Actions): 0.4758531153202057, F1 Score (Actions): tensor([0.5795, 0.4166, 0.5290, 0.5898, 0.7592, 0.7077, 0.6905, 0.0000, 0.0000,\n",
      "        0.2255, 0.8770, 0.3354])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1629/1629 [07:10<00:00,  3.79it/s]\n",
      "100%|██████████| 482/482 [00:58<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 2.14124357756271\n",
      "Validation Loss: 3.4137045541612383\n",
      "P_SCORE: 1.254302142709891\n",
      "Validation CCC (Valence-Arousal): 0.5129553317502198, Valence: 0.5216384013749967, Arousal: 0.504272262125443\n",
      "F1 Score_ABAW (Emotions): 0.26484567394146763, F1 Score (Emotions per class): [0.43383475 0.23718887 0.         0.19091967 0.46082831 0.26355966\n",
      " 0.15860058 0.37383354]\n",
      "F1 Score Mean (Actions): 0.47650113701820374, F1 Score (Actions): tensor([0.5758, 0.4108, 0.5343, 0.6193, 0.7651, 0.7093, 0.6908, 0.0000, 0.0000,\n",
      "        0.2110, 0.8771, 0.3246])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 805/1629 [03:38<03:43,  3.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a22119dc19e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_val_arousal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchallenges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_arousal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emotions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_val_arousal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchallenges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_arousal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emotions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mP_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d3950fc7e9ad>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    results = evaluate_model(model, test_loader, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    P_score = results[0] + (results[7] or 0) + (results[6] or 0)\n",
    "    val_loss = results[5]\n",
    "    if P_score > best_P_Score:\n",
    "        best_P_Score = P_score\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    print(f\"P_SCORE: {results[0] + (results[7] or 0) + (results[6] or 0)}\")\n",
    "    if 'val_arousal' in challenges:\n",
    "        print(f\"Validation CCC (Valence-Arousal): {results[0]}, Valence: {results[1]}, Arousal: {results[2]}\")\n",
    "    if 'emotions' in challenges:\n",
    "        print(f\"F1 Score_ABAW (Emotions): {results[7]}, F1 Score (Emotions per class): {results[3]}\")\n",
    "    if 'actions' in challenges:\n",
    "        print(f\"F1 Score Mean (Actions): {results[6]}, F1 Score (Actions): {results[4]}\")\n",
    "\n",
    "    torch.save(best_model_state, 'best_multitask_model_att.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2887961341647458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_P_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Model Training for Each Task\n",
    "tasks = ['val_arousal', 'emotions', 'actions']\n",
    "for task in tasks:\n",
    "    model = DDAMNet(num_class=8, num_head=2, pretrained=False, train_val_arousal=(task == 'val_arousal'), train_emotions=(task == 'emotions'), train_actions=(task == 'actions'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    freeze_all_layers(model)\n",
    "    unfreeze_layers(model, layers_to_unfreeze)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=(task,))\n",
    "        results = evaluate_model(model, test_loader, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=(task,))\n",
    "        P_score = (results[0] or 0) + (results[7] or 0) + (results[6] or 0)\n",
    "        val_loss = results[5]\n",
    "        if P_score < best_P_Score:\n",
    "            best_P_Score = P_score\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "        print(f\"Validation Loss: {val_loss}\")\n",
    "        print(f\"P_SCORE: {P_score}\")\n",
    "        if task == 'val_arousal':\n",
    "            print(f\"Validation CCC (Valence-Arousal): {results[0]}, Valence: {results[1]}, Arousal: {results[2]}\")\n",
    "        elif task == 'emotions':\n",
    "            print(f\"F1 Score_ABAW (Emotions): {results[7]}, F1 Score (Emotions per class): {results[3]}\")\n",
    "        elif task == 'actions':\n",
    "            print(f\"F1 Score Mean (Actions): {results[6]}, F1 Score (Actions): {results[4]}\")\n",
    "\n",
    "    torch.save(best_model_state, f'best_model_{task}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Thresholds: [0.43 0.35 0.37 0.23 0.43 0.38 0.32 0.1  0.1  0.55 0.6  0.32]\n",
      "Best F1 Scores: [0.7064853  0.67051531 0.74625491 0.68399251 0.75026711 0.75133624\n",
      " 0.78461797 0.50199402 0.55480202 0.64053554 0.73846926 0.64203661]\n",
      "Final Macro-Average F1 Score: 0.5068875804857068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the range of thresholds to search\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Initialize the best thresholds and corresponding best F1 scores\n",
    "best_thresholds = np.zeros(pred_action_units.shape[1])\n",
    "best_f1_scores = np.zeros(pred_action_units.shape[1])\n",
    "\n",
    "# Iterate over each index\n",
    "for i in range(pred_action_units.shape[1]):\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "    for threshold in thresholds:\n",
    "        # Apply threshold\n",
    "        pred_binary = (pred_action_units[:, i] >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(true_action_units[:, i], pred_binary, average=\"macro\")\n",
    "        \n",
    "        # Check if this is the best F1 score\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = threshold\n",
    "    \n",
    "    # Store the best threshold and F1 score\n",
    "    best_thresholds[i] = best_thresh\n",
    "    best_f1_scores[i] = best_f1\n",
    "\n",
    "# Output the best thresholds for each index\n",
    "print(\"Best Thresholds:\", best_thresholds)\n",
    "print(\"Best F1 Scores:\", best_f1_scores)\n",
    "\n",
    "# Apply the best thresholds to get the final binary predictions\n",
    "pred_action_units_binary_optimal = np.zeros(pred_action_units.shape)\n",
    "for i in range(pred_action_units.shape[1]):\n",
    "    pred_action_units_binary_optimal[:, i] = (pred_action_units[:, i] >= best_thresholds[i]).astype(int)\n",
    "\n",
    "# Calculate the final macro-average F1 score with the best thresholds\n",
    "final_f1_action_units = f1_score(true_action_units, pred_action_units_binary_optimal, average=\"macro\")\n",
    "print(\"Final Macro-Average F1 Score:\", final_f1_action_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure (P): 1.3306199130919016\n"
     ]
    }
   ],
   "source": [
    "performance_measure = (ccc_valence + ccc_arousal) / 2 + f1_expressions + final_f1_action_units\n",
    "\n",
    "print(f\"Performance Measure (P): {performance_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
