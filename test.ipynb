{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original predictions:\n",
      "tensor([0.9163, 0.4702, 0.0240, 0.3048, 0.3818, 0.9537, 0.6381, 0.5904, 0.1319,\n",
      "        0.8142, 0.7906, 0.3852])\n",
      "\n",
      "Binary predictions with single threshold (0.5):\n",
      "tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "\n",
      "Binary predictions with multiple thresholds:\n",
      "tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def apply_binary_threshold(tensor, threshold):\n",
    "    \"\"\"\n",
    "    Apply a binary threshold to a tensor.\n",
    "    \n",
    "    Args:\n",
    "    - tensor (torch.Tensor): Input tensor to apply threshold to.\n",
    "    - threshold (float or list of float): Threshold value(s). If a single float, it applies the same threshold to all elements.\n",
    "      If a list, each element in the list corresponds to the threshold for the corresponding element in the tensor.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: Binary thresholded tensor.\n",
    "    \"\"\"\n",
    "    if isinstance(threshold, float):\n",
    "        return (tensor >= threshold).float()\n",
    "    elif isinstance(threshold, list):\n",
    "        if len(threshold) != tensor.size(0):\n",
    "            raise ValueError(\"Number of thresholds must match the number of elements in the tensor.\")\n",
    "        return torch.tensor([1.0 if tensor[i] >= threshold[i] else 0.0 for i in range(tensor.size(0))])\n",
    "    else:\n",
    "        raise TypeError(\"Threshold must be either a float or a list of floats.\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming predictions[2] is a tensor with 12 elements\n",
    "predictions = torch.rand(12)  # Example tensor of random values\n",
    "print(\"Original predictions:\")\n",
    "print(predictions)\n",
    "\n",
    "# Applying a single threshold to all elements\n",
    "threshold = 0.5\n",
    "binary_predictions_single_threshold = apply_binary_threshold(predictions, threshold)\n",
    "print(\"\\nBinary predictions with single threshold (0.5):\")\n",
    "print(binary_predictions_single_threshold)\n",
    "\n",
    "# Applying different thresholds to each element\n",
    "thresholds = [0.44, 0.36, 0.39, 0.34, 0.46, 0.47, 0.38, 0.11, 0.1,  0.49, 0.62, 0.31]\n",
    "binary_predictions_multiple_thresholds = apply_binary_threshold(predictions, thresholds)\n",
    "print(\"\\nBinary predictions with multiple thresholds:\")\n",
    "print(binary_predictions_multiple_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7403/51159 [06:17<39:32, 18.44it/s]  "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "from networks.DDAM_ABAW import DDAMNet\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the image preprocessing function\n",
    "def preprocess_image(image_path, transform):\n",
    "    try:\n",
    "        image = Image.open(os.path.join(\"cropped_aligned_test\", image_path)).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "        return image_tensor\n",
    "    except UnidentifiedImageError as e:\n",
    "        print(f\"Skipping image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to read the text file and return a list of image paths\n",
    "def read_image_paths(txt_file):\n",
    "    with open(txt_file, 'r') as file:\n",
    "        image_paths = [line.rstrip(', \\n') for line in file if line.strip()]\n",
    "    return image_paths\n",
    "\n",
    "# Function to write results back to the text file\n",
    "def write_results(txt_file, results):\n",
    "    with open(txt_file, 'w') as file:\n",
    "        file.write(\"image,valence,arousal,expression,aus\" + \"\\n\")\n",
    "        for result in results:\n",
    "            valence = round(result['valence'], 2)\n",
    "            arousal = round(result['arousal'], 2)\n",
    "            aus_str = ','.join(map(str, result['aus'].astype(int)))  # Ensure aus are integers\n",
    "            file.write(f\"{result['image']},{valence},{arousal},{result['expression']},{aus_str}\\n\")\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DDAMNet(num_class=8, num_head=2, pretrained=False, train_val_arousal=True, train_emotions=True, train_actions=True)\n",
    "model_path = 'best_multitask_model_all.pth'\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define transformations to apply to the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Read the image paths from the txt file\n",
    "txt_file = 'MTL.txt'\n",
    "txt_results = \"MTL_results.txt\"\n",
    "image_paths = read_image_paths(txt_file)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each image and get predictions\n",
    "with torch.no_grad():\n",
    "    for image_path in tqdm(image_paths[1:]):\n",
    "        image_tensor = preprocess_image(image_path, transform)\n",
    "        if image_tensor is None:\n",
    "            results.append({\n",
    "            'image': image_path,\n",
    "            'valence': 0,\n",
    "            'arousal': 0,\n",
    "            'expression': 0,\n",
    "            'aus': np.zeros(12)\n",
    "            })\n",
    "        else:\n",
    "        \n",
    "            image_tensor = image_tensor.to(device)\n",
    "            \n",
    "            predictions = model(image_tensor)\n",
    "            \n",
    "            # Assuming the model returns valence, arousal, expression, and aus\n",
    "            valence = predictions[0][0][0].item()\n",
    "            arousal = predictions[0][0][1].item()\n",
    "            expression = np.argmax(predictions[1].cpu()).item()  # Move tensor to CPU before using np.argmax\n",
    "            \n",
    "            # Apply binary threshold\n",
    "            thresholds = [0.44, 0.36, 0.39, 0.34, 0.46, 0.47, 0.38, 0.11, 0.1,  0.49, 0.62, 0.31]\n",
    "            aus = torch.tensor([1.0 if val >= thresholds[i] else 0.0 for i, val in enumerate(predictions[2][0])])\n",
    "            \n",
    "            results.append({\n",
    "                'image': image_path,\n",
    "                'valence': valence,\n",
    "                'arousal': arousal,\n",
    "                'expression': expression,\n",
    "                'aus': aus.cpu().numpy()\n",
    "            })\n",
    "\n",
    "# Write the results back to the text file\n",
    "write_results(txt_results, results)\n",
    "\n",
    "print(\"Processing and writing results completed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
