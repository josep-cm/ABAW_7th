{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "#from networks.DDAM import DDAMNet\n",
    "from networks.DDAM_ABAW import DDAMNet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from keras.utils import Sequence\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to freeze all layers\n",
    "def freeze_all_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_all_layers(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Function to unfreeze specific layers\n",
    "def unfreeze_layers(model, layer_names):\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer_name in name for layer_name in layer_names):\n",
    "            param.requires_grad = True\n",
    "\n",
    "def freeze_batchnorm_layers(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
    "            module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the test_transforms outside the class\n",
    "IMG_SIZE = 112\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])  \n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([\n",
    "                transforms.RandomAffine(20, scale=(0.8, 1), translate=(0.2, 0.2)),\n",
    "            ], p=0.7),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=1, scale=(0.05, 0.05)),\n",
    "        ])\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, main_folder, mode, batch_size=32, image_size=(260, 260), n_classes_3=8, shuffle=True, device='cpu', transforms=test_transforms):\n",
    "        'Initialization'\n",
    "        self.main_folder = main_folder\n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.n_classes_3 = n_classes_3\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.device = device\n",
    "        self.transforms = transforms\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            self.targets_csv = '../keras_vggface_master/filtered_training_set_annotations.csv'\n",
    "        elif self.mode == 'val':\n",
    "            self.targets_csv = '../keras_vggface_master/filtered_validation_set_annotations.csv'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Mode must be 'train' or 'val'.\")\n",
    "\n",
    "        # Load the CSV to get the total number of samples\n",
    "        self.targets_df = pd.read_csv(self.targets_csv)\n",
    "        self.list_IDs = self.targets_df.index.tolist()\n",
    "\n",
    "        \n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, 3, *self.image_size), dtype=np.float32)\n",
    "        y = [[] for _ in range(3)]  # Assuming 3 target arrays (valence/arousal, emotions, actions)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            row = self.targets_df.iloc[ID]\n",
    "            image_path = os.path.join(self.main_folder, row['image'])\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            # Apply transformations\n",
    "            image = self.transforms(image)\n",
    "            X[i,] = image.numpy()\n",
    "\n",
    "            y[0].append([row[1], row[2]])  # First target value (valence/arousal)\n",
    "            target_3_one_hot = to_categorical(row[3], num_classes=self.n_classes_3)\n",
    "            y[1].append(target_3_one_hot)\n",
    "            \n",
    "            y[2].append([row[col_start] for col_start in range(4, len(row))])\n",
    "            \n",
    "\n",
    "\n",
    "        X_tensor = torch.tensor(X).to(self.device)\n",
    "        y_tensor = [torch.tensor(np.array(sublist)).to(self.device) for sublist in y]  # Convert each sublist to tensor\n",
    "\n",
    "    \n",
    "        \n",
    "        return X_tensor, y_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCC(y_true, y_pred):\n",
    "    y_true_mean = torch.mean(y_true)\n",
    "    y_pred_mean = torch.mean(y_pred)\n",
    "    covariance = torch.mean((y_true - y_true_mean) * (y_pred - y_pred_mean))\n",
    "    y_true_var = torch.var(y_true)\n",
    "    y_pred_var = torch.var(y_pred)\n",
    "    ccc = (2 * covariance) / (y_true_var + y_pred_var + (y_true_mean - y_pred_mean)**2 + 1e-8)\n",
    "    return ccc\n",
    "\n",
    "def CCC_loss(y_true, y_pred):\n",
    "    return 1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Positives = torch.sum(torch.round(torch.clamp(y_true, 0, 1)))\n",
    "        recall = TP / (Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return recall \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = torch.sum(torch.round(torch.clamp(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return precision \n",
    "    \n",
    "    # Initialize lists to store precision, recall, and f1 scores per class\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "\n",
    "    # Iterate over each class\n",
    "    for class_idx in range(y_true.shape[1]):\n",
    "        precision = precision_m(y_true[:, class_idx], y_pred[:, class_idx])\n",
    "        recall = recall_m(y_true[:, class_idx], y_pred[:, class_idx])\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * ((precision * recall) / (precision + recall + 1e-7))\n",
    "        \n",
    "        # Append scores to lists\n",
    "        precision_per_class.append(precision.item())\n",
    "        recall_per_class.append(recall.item())\n",
    "        f1_per_class.append(f1.item())\n",
    "    \n",
    "    # Overall macro F1 score\n",
    "    macro_f1 = torch.mean(torch.tensor(f1_per_class))\n",
    "    \n",
    "    # Return overall F1 score and F1 score per class\n",
    "    return macro_f1.item(), f1_per_class\n",
    "\n",
    "def f1_metric_o(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Positives = torch.sum(torch.round(torch.clamp(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return recall \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = torch.sum(torch.round(torch.clamp(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives + 1e-7)  # Adding a small epsilon for numerical stability\n",
    "        return precision \n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    \n",
    "    f1 = 2 * ((precision * recall) / (precision + recall + 1e-7))  # Adding a small epsilon for numerical stability\n",
    "    \n",
    "    return f1, f1\n",
    "\n",
    "def f1_score_actions(y_true, y_pred, threshold=0.5):\n",
    "    # Convert predicted probabilities to binary predictions\n",
    "    y_pred_binary = (y_pred >= threshold).float()\n",
    "    \n",
    "    # Initialize lists to store F1 scores for each AU\n",
    "    F1s = []\n",
    "    \n",
    "    # Calculate F1 score for each AU\n",
    "    for i in range(y_true.shape[1]):\n",
    "        # Extract true and predicted values for the current AU\n",
    "        y_true_au = y_true[:, i]\n",
    "        y_pred_au = y_pred_binary[:, i]\n",
    "        \n",
    "        # Calculate True Positives, False Positives, False Negatives\n",
    "        TP = torch.sum(y_true_au * y_pred_au)\n",
    "        FP = torch.sum((1 - y_true_au) * y_pred_au)\n",
    "        FN = torch.sum(y_true_au * (1 - y_pred_au))\n",
    "        \n",
    "        # Calculate Precision, Recall, and F1 Score\n",
    "        precision = TP / (TP + FP + 1e-7)  # Adding epsilon to avoid division by zero\n",
    "        recall = TP / (TP + FN + 1e-7)  # Adding epsilon to avoid division by zero\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-7)  # Adding epsilon to avoid division by zero\n",
    "        \n",
    "        F1s.append(f1.item())\n",
    "    \n",
    "    F1s = torch.tensor(F1s)\n",
    "    F1_mean = torch.mean(F1s)\n",
    "    \n",
    "    return F1s, F1_mean.item()\n",
    "\n",
    "\n",
    "def compute_AU_F1(pred,label):\n",
    "    pred = np.array(pred)\n",
    "    label = np.array(label)\n",
    "    AU_targets = [[] for i in range(12)]\n",
    "    AU_preds = [[] for i in range(12)]\n",
    "    F1s = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(12):\n",
    "            p = pred[i,j]\n",
    "            if p>=0.5:\n",
    "                AU_preds[j].append(1)\n",
    "            else:\n",
    "                AU_preds[j].append(0)\n",
    "            AU_targets[j].append(label[i,j])\n",
    "    \n",
    "    for i in range(12):\n",
    "        F1s.append(f1_score(AU_targets[i], AU_preds[i]))\n",
    "\n",
    "    F1s = np.array(F1s)\n",
    "    F1_mean = np.mean(F1s)\n",
    "    return F1s, F1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = sys.float_info.epsilon\n",
    "class AttentionLoss(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(AttentionLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        num_head = len(x)\n",
    "        loss = 0\n",
    "        cnt = 0\n",
    "        if num_head > 1:\n",
    "            for i in range(num_head-1):\n",
    "                for j in range(i+1, num_head):\n",
    "                    mse = F.mse_loss(x[i], x[j])\n",
    "                    cnt = cnt+1\n",
    "                    loss = loss+mse\n",
    "            loss = cnt/(loss + eps)\n",
    "        else:\n",
    "            loss = 0\n",
    "        return loss\n",
    "    \n",
    "\n",
    "def compute_EXP_F1(pred, target):\n",
    "    pred_labels = []\n",
    "    pred = np.array(pred)\n",
    "    target = np.array(target)\n",
    "    \n",
    "    # Convert one-hot encoded target to class labels\n",
    "    if len(target.shape) > 1 and target.shape[1] > 1:\n",
    "        target = np.argmax(target, axis=1)\n",
    "    \n",
    "    # Convert predictions to class labels\n",
    "    for i in range(pred.shape[0]):\n",
    "        l = np.argmax(pred[i])\n",
    "        pred_labels.append(l)\n",
    "        \n",
    "    # Compute F1 scores\n",
    "    F1s = f1_score(target, pred_labels, average=None)\n",
    "    macro_f1 = np.mean(F1s)\n",
    "    return F1s, macro_f1\n",
    "\n",
    "\n",
    "def compute_AU_F1(pred,label):\n",
    "    pred = np.array(pred)\n",
    "    label = np.array(label)\n",
    "    AU_targets = [[] for i in range(12)]\n",
    "    AU_preds = [[] for i in range(12)]\n",
    "    F1s = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(12):\n",
    "            p = pred[i,j]\n",
    "            if p>=0.5:\n",
    "                AU_preds[j].append(1)\n",
    "            else:\n",
    "                AU_preds[j].append(0)\n",
    "            AU_targets[j].append(label[i,j])\n",
    "    \n",
    "    for i in range(12):\n",
    "        F1s.append(f1_score(AU_targets[i], AU_preds[i]))\n",
    "\n",
    "    F1s = np.array(F1s)\n",
    "    F1_mean = np.mean(F1s)\n",
    "    return F1s, F1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train and evaluation functions\n",
    "def train_model(model, train_loader, optimizer, criterion_val_arousal=None, criterion_emotions=None, criterion_actions=None, criterion_at=None, device=None, challenges=('val_arousal', 'emotions', 'actions')):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels_val_arousal = labels[0].to(device) if 'val_arousal' in challenges else None\n",
    "        labels_emotions = labels[1].to(device) if 'emotions' in challenges else None\n",
    "        labels_actions = labels[2].to(device) if 'actions' in challenges else None\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        val_arousal = outputs[0] if 'val_arousal' in challenges else None\n",
    "        emotions = outputs[1] if 'emotions' in challenges else None\n",
    "        actions = outputs[2] if 'actions' in challenges else None\n",
    "        heads = outputs[-1] if criterion_at else None\n",
    "        \n",
    "        loss = 0.0\n",
    "        if 'val_arousal' in challenges:\n",
    "            loss_val_arousal = criterion_val_arousal(val_arousal, labels_val_arousal)\n",
    "            loss += loss_val_arousal\n",
    "        if 'emotions' in challenges:\n",
    "            emotions_argmax = torch.argmax(labels_emotions, dim=1)\n",
    "            loss_emotions = criterion_emotions(emotions, emotions_argmax)\n",
    "            loss += loss_emotions\n",
    "        if 'actions' in challenges:\n",
    "            loss_actions = criterion_actions(actions.float(), labels_actions.float())\n",
    "            loss += loss_actions\n",
    "        if criterion_at:\n",
    "            loss += 0.1 * criterion_at(heads)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion_val_arousal=None, criterion_emotions=None, criterion_actions=None, criterion_at=None, device=None, challenges=('val_arousal', 'emotions', 'actions')):\n",
    "    model.eval()\n",
    "    val_arousal_preds, emotions_preds, actions_preds = [], [], []\n",
    "    val_arousal_labels, emotions_labels, actions_labels = [], [], []\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels_val_arousal = labels[0].to(device) if 'val_arousal' in challenges else None\n",
    "            labels_emotions = labels[1].to(device) if 'emotions' in challenges else None\n",
    "            labels_actions = labels[2].to(device) if 'actions' in challenges else None\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            val_arousal = outputs[0] if 'val_arousal' in challenges else None\n",
    "            emotions = outputs[1] if 'emotions' in challenges else None\n",
    "            actions = outputs[2] if 'actions' in challenges else None\n",
    "            heads = outputs[-1] if criterion_at else None\n",
    "            \n",
    "            loss = 0.0\n",
    "            if 'val_arousal' in challenges:\n",
    "                loss_val_arousal = criterion_val_arousal(val_arousal, labels_val_arousal)\n",
    "                loss += loss_val_arousal\n",
    "                val_arousal_preds.append(val_arousal.cpu())\n",
    "                val_arousal_labels.append(labels_val_arousal.cpu())\n",
    "            if 'emotions' in challenges:\n",
    "                emotions_argmax = torch.argmax(labels_emotions, dim=1)\n",
    "                loss_emotions = criterion_emotions(emotions, emotions_argmax)\n",
    "                loss += loss_emotions\n",
    "                emotions_preds.append(emotions.cpu())\n",
    "                emotions_labels.append(labels_emotions.cpu())\n",
    "            if 'actions' in challenges:\n",
    "                loss_actions = criterion_actions(actions.float(), labels_actions.float())\n",
    "                loss += loss_actions\n",
    "                actions_preds.append(actions.cpu())\n",
    "                actions_labels.append(labels_actions.cpu())\n",
    "            if criterion_at:\n",
    "                loss += 0.1 * criterion_at(heads)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(test_loader)\n",
    "\n",
    "    ccc_val_arousal = ccc_valence = ccc_arousal = None\n",
    "    f1_emotions = f1_emotion_mean = None\n",
    "    f1_actions = f1_mean = None\n",
    "\n",
    "    if 'val_arousal' in challenges:\n",
    "        val_arousal_preds = torch.cat(val_arousal_preds)\n",
    "        val_arousal_labels = torch.cat(val_arousal_labels)\n",
    "        ccc_valence = CCC(val_arousal_labels[:, 0].cpu(), val_arousal_preds[:, 0].cpu()).item()\n",
    "        ccc_arousal = CCC(val_arousal_labels[:, 1].cpu(), val_arousal_preds[:, 1].cpu()).item()\n",
    "        ccc_val_arousal = (ccc_valence + ccc_arousal) / 2\n",
    "    if 'emotions' in challenges:\n",
    "        emotions_preds = torch.cat(emotions_preds)\n",
    "        emotions_labels = torch.cat(emotions_labels)\n",
    "        f1_emotions, f1_emotion_mean = compute_EXP_F1(emotions_preds, emotions_labels)\n",
    "    if 'actions' in challenges:\n",
    "        actions_preds = torch.cat(actions_preds)\n",
    "        actions_labels = torch.cat(actions_labels)\n",
    "        f1_actions, f1_mean = f1_score_actions(actions_labels, actions_preds, threshold=0.5)\n",
    "\n",
    "    return ccc_val_arousal, ccc_valence, ccc_arousal, f1_emotions, f1_actions, avg_val_loss, f1_mean, f1_emotion_mean\n",
    "\n",
    "\n",
    "\n",
    "challenges=('val_arousal', 'emotions', 'actions')\n",
    "num_epochs = 10\n",
    "learning_rate = 0.00001\n",
    "model_path = 'checkpoints_ver2.0/affecnet8_epoch25_acc0.6469.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define dataloaders (placeholders, replace with actual DataLoader instances)\n",
    "# Initialize the generator\n",
    "train_loader = DataGenerator(\"../cropped_aligned\", mode=\"train\", batch_size=32, image_size=(112, 112), shuffle=True, device='cuda', transforms=train_transforms)\n",
    "test_loader = DataGenerator(\"../cropped_aligned\",mode=\"val\",batch_size=32 ,image_size=(112,112), shuffle=False, device='cuda', transforms=test_transforms)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_val_arousal = CCC_loss\n",
    "criterion_emotions = nn.CrossEntropyLoss()\n",
    "criterion_actions = nn.BCELoss()\n",
    "criterion_at = AttentionLoss()\n",
    "\n",
    "# Multitask Model Training\n",
    "model = DDAMNet(num_class=8, num_head=2, pretrained=False, train_val_arousal=True, train_emotions=True, train_actions=True)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "freeze_all_layers(model)\n",
    "layers_to_unfreeze = ['custom_classifier', \"Linear\",\"cat_head\",\"features\"]#\"cat_head\",,\"features\"\n",
    "unfreeze_layers(model, layers_to_unfreeze)\n",
    "#freeze_batchnorm_layers(model)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "best_P_Score = float('-inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    results = evaluate_model(model, test_loader, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    P_score = results[0] + (results[7] or 0) + (results[6] or 0)\n",
    "    val_loss = results[5]\n",
    "    if P_score > best_P_Score:\n",
    "        best_P_Score = P_score\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    print(f\"P_SCORE: {results[0] + (results[7] or 0) + (results[6] or 0)}\")\n",
    "    if 'val_arousal' in challenges:\n",
    "        print(f\"Validation CCC (Valence-Arousal): {results[0]}, Valence: {results[1]}, Arousal: {results[2]}\")\n",
    "    if 'emotions' in challenges:\n",
    "        print(f\"F1 Score_ABAW (Emotions): {results[7]}, F1 Score (Emotions per class): {results[3]}\")\n",
    "    if 'actions' in challenges:\n",
    "        print(f\"F1 Score Mean (Actions): {results[6]}, F1 Score (Actions): {results[4]}\")\n",
    "\n",
    "    torch.save(best_model_state, 'best_multitask_model_att2.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    results = evaluate_model(model, test_loader, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=('val_arousal', 'emotions', 'actions'))\n",
    "    P_score = results[0] + (results[7] or 0) + (results[6] or 0)\n",
    "    val_loss = results[5]\n",
    "    if P_score > best_P_Score:\n",
    "        best_P_Score = P_score\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "    print(f\"P_SCORE: {results[0] + (results[7] or 0) + (results[6] or 0)}\")\n",
    "    if 'val_arousal' in challenges:\n",
    "        print(f\"Validation CCC (Valence-Arousal): {results[0]}, Valence: {results[1]}, Arousal: {results[2]}\")\n",
    "    if 'emotions' in challenges:\n",
    "        print(f\"F1 Score_ABAW (Emotions): {results[7]}, F1 Score (Emotions per class): {results[3]}\")\n",
    "    if 'actions' in challenges:\n",
    "        print(f\"F1 Score Mean (Actions): {results[6]}, F1 Score (Actions): {results[4]}\")\n",
    "\n",
    "    torch.save(best_model_state, 'best_multitask_model_att.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_P_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Model Training for Each Task\n",
    "tasks = ['val_arousal', 'emotions', 'actions']\n",
    "for task in tasks:\n",
    "    model = DDAMNet(num_class=8, num_head=2, pretrained=False, train_val_arousal=(task == 'val_arousal'), train_emotions=(task == 'emotions'), train_actions=(task == 'actions'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    freeze_all_layers(model)\n",
    "    unfreeze_layers(model, layers_to_unfreeze)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=(task,))\n",
    "        results = evaluate_model(model, test_loader, criterion_val_arousal, criterion_emotions, criterion_actions, criterion_at, device, challenges=(task,))\n",
    "        P_score = (results[0] or 0) + (results[7] or 0) + (results[6] or 0)\n",
    "        val_loss = results[5]\n",
    "        if P_score < best_P_Score:\n",
    "            best_P_Score = P_score\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "        print(f\"Validation Loss: {val_loss}\")\n",
    "        print(f\"P_SCORE: {P_score}\")\n",
    "        if task == 'val_arousal':\n",
    "            print(f\"Validation CCC (Valence-Arousal): {results[0]}, Valence: {results[1]}, Arousal: {results[2]}\")\n",
    "        elif task == 'emotions':\n",
    "            print(f\"F1 Score_ABAW (Emotions): {results[7]}, F1 Score (Emotions per class): {results[3]}\")\n",
    "        elif task == 'actions':\n",
    "            print(f\"F1 Score Mean (Actions): {results[6]}, F1 Score (Actions): {results[4]}\")\n",
    "\n",
    "    torch.save(best_model_state, f'best_model_{task}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of thresholds to search\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "# Initialize the best thresholds and corresponding best F1 scores\n",
    "best_thresholds = np.zeros(pred_action_units.shape[1])\n",
    "best_f1_scores = np.zeros(pred_action_units.shape[1])\n",
    "\n",
    "# Iterate over each index\n",
    "for i in range(pred_action_units.shape[1]):\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "    for threshold in thresholds:\n",
    "        # Apply threshold\n",
    "        pred_binary = (pred_action_units[:, i] >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(true_action_units[:, i], pred_binary, average=\"macro\")\n",
    "        \n",
    "        # Check if this is the best F1 score\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = threshold\n",
    "    \n",
    "    # Store the best threshold and F1 score\n",
    "    best_thresholds[i] = best_thresh\n",
    "    best_f1_scores[i] = best_f1\n",
    "\n",
    "# Output the best thresholds for each index\n",
    "print(\"Best Thresholds:\", best_thresholds)\n",
    "print(\"Best F1 Scores:\", best_f1_scores)\n",
    "\n",
    "# Apply the best thresholds to get the final binary predictions\n",
    "pred_action_units_binary_optimal = np.zeros(pred_action_units.shape)\n",
    "for i in range(pred_action_units.shape[1]):\n",
    "    pred_action_units_binary_optimal[:, i] = (pred_action_units[:, i] >= best_thresholds[i]).astype(int)\n",
    "\n",
    "# Calculate the final macro-average F1 score with the best thresholds\n",
    "final_f1_action_units = f1_score(true_action_units, pred_action_units_binary_optimal, average=\"macro\")\n",
    "print(\"Final Macro-Average F1 Score:\", final_f1_action_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measure = (ccc_valence + ccc_arousal) / 2 + f1_expressions + final_f1_action_units\n",
    "\n",
    "print(f\"Performance Measure (P): {performance_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
